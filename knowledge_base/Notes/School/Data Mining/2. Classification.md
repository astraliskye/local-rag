Input: collection of records (training set)
- Each record has a class attribute aka label. Can be discreet or continuous
- Should have the same distribution of classes as the test set
- Has the same statistical features as the test set
Goal: find a way to express class attributes as a function of other attributes and then use that function to identify unlabeled records

Test set: collection of records without the corresponding class attribute
- Used to determine the accuracy of the model

Induction: training model is given to learning algorithm and the algorithm learns the function that relates

Deduction: model is given unlabeled data and tasked with classifying records with unknown labels

Classification techniques
- Decision-tree based methods
- Rules based methods
- Memory based methods
- Neural network
- Naive Bayes and Bayesian Belief networks
- Support Vector Machines
# Classification Tasks
## Decision Trees
Decision trees are basically a bunch of if-elif-else statements based on data attributes.
Internal nodes are called "splitting attributes," leaf nodes are the class attributes.
More than one tree can fit the data.
Root node has no incoming edges and zero or more outgoing edges
Hunt's algorithm: decision tree induction algorithm that can learn any decision tree
- CART, ID3, C4.5, SLIQ, SPRINT are modifications of this algorithm
### Hunt's algorithm
D is the set of training records that reach a node t
1. If D contains records that belong to the same class, then t is a leaf node for that class
2. If D contains zero records, then t is a leaf node of the default class
3. If D contains records that belong to more than one class, use an attribute test to split the data into smaller subsets. Recursively apply this procedure to each subset

Tree Induction strategies
- Greedy
	- Split records based on an attribute test that optimizes certain criterion
Issues
- How to determine attribute test condition
- When to stop splitting

Test conditions
- Nominal attributes can be split individually or in groups
- Ordinal attributes can be split in a way that causes them to lose their ordinality. 

Binary split: two pathways after the decision
Multiway split: more than two pathways after every split

Continuous attribute discretization. Splitting a range up into multiple ranges. Where it splits can be static or dynamic (variable)

Ideally want asymmetric distribution of classes. That means that each decision will meaningfully push you toward classifying that record. Sets which evenly distribute classes are impure and are considered non-homogenous. Sets which skew selected classes are pure and are said to be homogenous 

Want to use tests that can be applied to new records. This makes IDs very bad for decision tree tests (overfitting)

## Node Impurity
A pure node means less confusion. Each pure node decision leans toward one class over others.

Measures of impurity:
- Gini index
- Entropy
- Misclassification error
How to find the best split
1. For each possible split
	1. m0 is the impurity measure of the records going into the decision node
	2. m1 is the measure of the impurity of the left most path from the decision node. m2 is the measure of the impurity of the second left most path from the decision node. And so on
	3. Combine m1, m2, ... in some way
	4. Use information gain (purity gain) m0 - m1m2... to compare possible decision nodes
		1. Which value for gain is best depends

### Gini index
A measure of impurity ranging from 0 to 1.

Computationally inexpensive when compared to Entropy, another measure of impurity

Given t one of the output nodes and there are j outputs from that node. p(j|t) is the relative frequency of class j in node t
$$
GINI(t) = 1 - \sum_j[p(j | t)]^2
$$



## Node Impurity (How to determine splits)
A pure node means less confusion. Each pure node decision leans toward one class over others.

Measures of impurity:
- Gini index
- Entropy
- Misclassification error
How to find the best split
1. For each possible split
	1. m0 is the impurity measure of the records going into the decision node
	2. m1 is the measure of the impurity of the left most path from the decision node. m2 is the measure of the impurity of the second left most path from the decision node. And so on
	3. Combine m1, m2, ... in some way
	4. Use information gain (purity gain) m0 - m1m2... to compare possible decision nodes
		1. Which value for gain is best depends

Gain is the different between the information contained in the parent minus the weighted information contained in the children

$$
\Delta = I(parent) - \sum_{j=1}^{k} \frac{N(v_j)}{N}-I(v_j)
$$

### Gain Ratio (helps work against the tendency of gini index and entropy to optimize for a lot of tiny partitions/splits)
$$
GainRATIO_{split} = \frac{GAIN_{split}}{SplitINFO}
$$
Information contained in split
$$
SplitINFO=-\sum_{i=1}^k \frac{n_i}{n} log \frac{n_i}{n}
$$

### Gini index (aka Gini Impurity)
A measure of impurity ranging from 0 to 1.

Computationally inexpensive when compared to Entropy, another measure of impurity.

0 = all records belong to one class
1 - 1/n_c = all records are equally distributed among all classes
- n_c is the number of classes (don't quote me on that...)

Given t one of the decision nodes and there are j classes in that node. p(j|t) is the relative frequency of class j in node t
$$
GINI(t) = 1 - \sum_j[p(j | t)]^2
$$

Gini index for a split (weighted sum of gini nodes)
	k splits
	n_i = number of training data objects that came into node i
$$
GINI_{split}=\sum_{i=1}^k \frac{n_i}{n} GINI(i)
$$

Transforming continuous attributes to binary:
- Choose each entry as a unique value
- Choose a threshold to split up the range
### Entropy
t is a node

$$
Entropy(t) = -\sum_j p(j|t)logp(j|t)
$$$$
Error(t) = 1 - max P(i|t)
$$


## Finishing thoughts
Impurity measures favor attributes that have a large number of distinct values. They want to split on many values to get a lot of small, pure splits


## When to stop splitting
