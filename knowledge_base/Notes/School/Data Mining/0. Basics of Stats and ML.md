# Distribution
- Histogram: a distribution that counts occurrences of each value in a set
	- For continuous variables, break up the domain into equal-sized "buckets"
	- Cannot predict probabilities for "buckets" with zero 
- Distribution curve/normal distribution/gaussian distribution/probability density function
	- Function that models the probability of a particular event
	- The probability of a range of events is calculated by taking the area under the curve for all events
		- e.g. the probability of weighing a random mouse between 32 and 34 grams is the integral of the distribution curve from x=32 to x=34
		$$
			pr(\text{event will occur | mean = 32 and standard deviation = 2.5})
		$$
		- The vertical bar reads as "given"
	- Standard normal distribution: mean = 0, std dev = 1
	- Deviation: difference between a datapoint and the mean of the dataset
		- Used to calculate standard deviation and variance
		$$
		x-\overline x
		$$
	- Variance: measure of how much data points deviate from the mean
		- Sum of squares of the distance of each data point from the mean, all over the number of values in the dataset minus one
		- Here is an example for a 1-D data set
		$$
n = \text{number of elements in the distribution}
$$
			$$
\text{Whole population variance}: \sigma^2 = \frac{\sum_{i=1}^n (x_i - \overline x)^2}{n}
			$$
			$$
\text{Sample vairance}: s^2 = \frac{\sum_{i=1}^n (x_i - \overline x)^2}{n - 1}
			$$
	- Standard deviation: measure of how "spread out" the data is
		- Essentially just the square root of the variance
		- Used mostly because it makes intuitive sense
		- Same unit as the values being measured
# Likelihood vs Probability
Probability is the area under a fixed distribution
$$
pr(\text{data | distribution})
$$
Likelihood is determined when we have the event already. It is the y-axis value fixed data points with distributions that can be moved
$$
L(distribution | data)
$$
# Confusion Matrix
A method for measuring the effectiveness of classifiers
Example for analyzing a binary classifier:

| actual →<br>↓predicted | true               | false              |
| ---------------------- | ------------------ | ------------------ |
| true                   | True<br>Positives  | False<br>Positives |
| false                  | False<br>Negatives | True<br>Negatives  |
If there are more than two classes in the data set, the classifier will be of the shape n x n where n is the number of possible classes
- The main diagonal will contain information about how many times the model correctly classified records
# Cost Matrix
Assign weights essentially to TP, FP, FN, TN because not all models value each measurement equally. TN and TP should have costs of 0 or less

| actual →<br>↓predicted | true               | false              |
| ---------------------- | ------------------ | ------------------ |
| true                   | True<br>Positives  | False<br>Positives |
| false                  | False<br>Negatives | True<br>Negatives  |
# Classifiers
Logistic regression
Linear regression (least squares)
k-NN
Random forest
Decision tree
Bayes classifier
- Multimodal
- Gaussian
Support vector machines
## Measuring classifiers
Specificity
Sensitivity
ROC
AUC
Log loss
Methods
- Holdout
	- Reserve holdout some of the data for a test set and measure accuracy and other metrics against the test set only
	- Test set should have the same proportions as the training set
- Random subsampling
	- Randomly partition the data set into training and testing sets, run the model and analyze it, then re-partition and try again
Maximize precision and recall
Confusion matrix
- True positive rate (recall/sensitivity) - ratio of true positive out of all actual positives
- False negative rate - ration of false negatives to actual positives
- False positive rate - ratio of false positives to the amount of all actual negatives
- True negative rate - ratio of true negatives to actual negatives
- Specificity - ratio of true negatives to all actual negatives
- Precision - ratio of true positives to total classified positives
- Accuracy - ratio of correct classification (true positives and true negatives) to total classifications
	- Good metric when there is a balance of positive and negative classes
- F1 score (combined precision and recall)
	$$
F1=2 \cdot \frac{precision \cdot recall}{precision + recall}
	$$
# Bias and Variance
Bias: inability for machine learning method to capture the true relationship
- e.g. trying to represent a logarithmic relationship using linear regression
Variance: difference in fits between data sets for a given line of best fit
Sum of squares: method of testing lines of best fit in linear regression and related models
- Possible measurement for bias
- Measure both the training and testing set of data
Overfit: when the line of best fit fits the training set very well but not the testing set
- More complex models can tend to be overfit?
- Finding the sweet spot between simple and complex models
	- Regularization
	- Boosting
	- Bagging
# Cross Validation
Deciding which machine learning method is best for a particular task
After splitting data into chunks, cross validation trains each model with every combination of chunks (minus one for testing) and tests using the unused chunk and records the values
Four-fold cross-validation: cut input data into quarters
Ten-fold cross-validation: cut input data into ten segments
Leave One Out Cross Validation: have many chunks and only leave one out for testing
If model has a tuning parameter, can use cross-validation to test the same model with different values for that parameter
# Receiver Operating Characteristic
Analyze two models, for example when doing cross validation
Based on electronic transistors
Plots TPR vs FPR
Each axis is 0 to 1
# ToDo
- Linear regression
- Logistic regression
- Multiple regression
- Cross validation
- ROC and AUC
# Random notes
- Split available data up into training and testing data, in a way that preserves the ratio of classes in both sets
# ML Process
1. Take all data
2. Split into training data (75% maybe) and testing data (25% maybe)
3. Train model (parameter estimation)
4. Test model (evaluate model)